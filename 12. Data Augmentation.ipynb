{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5f13c3-5f9c-4abc-97ef-87bd2c81e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474c7b7e-8d93-4d6b-93b7-74a9c7b775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd58c13d-17f9-4258-a4fe-04882beb5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e137253-6e5c-4db0-9fc6-d0e0cf92c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train','test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366e20dd-6b21-435b-b5cd-d4990953dcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='cifar10',\n",
       "    full_name='cifar10/3.0.2',\n",
       "    description=\"\"\"\n",
       "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
       "    \"\"\",\n",
       "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
       "    data_path='C:\\\\Users\\\\Nirajan\\\\tensorflow_datasets\\\\cifar10\\\\3.0.2',\n",
       "    file_format=tfrecord,\n",
       "    download_size=162.17 MiB,\n",
       "    dataset_size=132.40 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'id': Text(shape=(), dtype=string),\n",
       "        'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
       "        author = {Alex Krizhevsky},\n",
       "        title = {Learning multiple layers of features from tiny images},\n",
       "        institution = {},\n",
       "        year = {2009}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51112790-e5e9-4be6-8562-98c619528099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32)/255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87d966c9-320b-49d2-adc8-fd7a571a715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    image = tf.image.resize(image, (32,32))\n",
    "\n",
    "    if tf.random.uniform((), minval=0, maxval=1) <=0.1:\n",
    "        image = tf.tile(tf.image.rgb_to_grayscale(image), [1,1,3])\n",
    "\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.1, upper=0.2)\n",
    "    image = tf.image.random_flip_left_right(image) # 50%\n",
    "    # image = tf.image.random_flip_up_down(image) # 50%\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e29a958b-e38b-4932-acf1-2f1dd54babc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8c30b56-4158-434d-aba9-38c94f147e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(8, 3, activation='relu'),\n",
    "        layers.Conv2D(16, 3, activation='relu'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.GlobalMaxPool2D(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "297ddaff-af0d-45fd-b637-65119f4a25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 8)         224       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,794\n",
      "Trainable params: 8,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12fe8f9f-00d0-4dd5-978e-ee5fa3711623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9013e60c-1658-4432-b2af-ebd33f16f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 16s 6ms/step - loss: 2.1196 - accuracy: 0.1961 - val_loss: 3.7912 - val_accuracy: 0.1234\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.9819 - accuracy: 0.2495 - val_loss: 3.8374 - val_accuracy: 0.1742\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.8980 - accuracy: 0.2909 - val_loss: 4.6807 - val_accuracy: 0.1853\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8436 - accuracy: 0.3145 - val_loss: 4.4297 - val_accuracy: 0.2083\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7891 - accuracy: 0.3389 - val_loss: 4.0063 - val_accuracy: 0.2361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab4ecb8310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs = 5,\n",
    "    validation_data = ds_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af03c8-675d-400c-8429-d26962dabc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
