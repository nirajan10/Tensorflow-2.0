{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89b381e-6eee-46fd-a2f5-90a7725a2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba874e6b-823d-450f-ae76-0a23e9a8d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc8238d-c892-4de6-8328-865407db37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5785ce-2458-4eed-b643-89fb4e16a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0a7362-7229-47bd-8f25-f0f927d4bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66934c62-3f6d-452b-95d2-84589f820c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# Setup for test Dataset\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4e909d-ea0c-46cd-8030-1f4c08fe9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b163d80-378e-4022-96ff-bd4a055aa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c22b92-5617-425b-9073-9b571712a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of Training Epoch 1\n",
      "Accuracy over epoch 0.9253000020980835\n",
      "\n",
      "Start of Training Epoch 2\n",
      "Accuracy over epoch 0.973716676235199\n",
      "\n",
      "Start of Training Epoch 3\n",
      "Accuracy over epoch 0.9813833236694336\n",
      "\n",
      "Start of Training Epoch 4\n",
      "Accuracy over epoch 0.9847833514213562\n",
      "\n",
      "Start of Training Epoch 5\n",
      "Accuracy over epoch 0.9880666732788086\n",
      "Accuracy over Test Set: 0.9818999767303467\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStart of Training Epoch {epoch+1}\")\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(ds_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch, training=True)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "\n",
    "    train_acc = acc_metric.result()\n",
    "    print(f\"Accuracy over epoch {train_acc}\")\n",
    "    acc_metric.reset_states()\n",
    "\n",
    "# Test Loop\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(ds_test):\n",
    "    y_pred = model(x_batch, training=False)\n",
    "    acc_metric.update_state(y_batch, y_pred)\n",
    "\n",
    "train_acc = acc_metric.result()\n",
    "print(f\"Accuracy over Test Set: {train_acc}\")\n",
    "acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e81076-fb6e-453e-b983-ac4f1d2c02e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
